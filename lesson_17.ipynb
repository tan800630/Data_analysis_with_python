{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter,defaultdict\n",
    "from __future__ import division\n",
    "\n",
    "#decision tree\n",
    "\n",
    "def entropy(class_probabilities):\n",
    "    return sum(-p*math.log(p,2)\n",
    "              for p in class_probabilities\n",
    "              if p) #p=0直接忽略\n",
    "\n",
    "def class_probabilities(labels):\n",
    "    total_count=len(labels)\n",
    "    return[count/total_count\n",
    "          for count in Counter(labels).values()]\n",
    "\n",
    "def data_entropy(labeled_data):\n",
    "    labels=[label for _,label in labeled_data]\n",
    "    probabilities=class_probabilities(labels)\n",
    "    return entropy(probabilities)\n",
    "\n",
    "\n",
    "# entropy of partition\n",
    "\n",
    "def partition_entropy(subsets):\n",
    "    \n",
    "    total_count=sum(len(subset) for subset in subsets)\n",
    "    return sum(data_entropy(subset)*len(subset)/total_count\n",
    "              for subset in subsets)\n",
    "\n",
    "def partition_by(inputs,attribute):\n",
    "    groups=defaultdict(list)\n",
    "    for input in inputs:\n",
    "        key=input[0][attribute]\n",
    "        groups[key].append(input)    \n",
    "    return groups\n",
    "\n",
    "def partition_entropy_by(inputs,attribute):\n",
    "    partitions=partition_by(inputs,attribute)\n",
    "    return partition_entropy(partitions.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 0.693536138896\n",
      "lang 0.860131712855\n",
      "tweets 0.704163610709\n",
      "phd 0.838042395061\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "\n",
    "inputs=[\n",
    "    ({'level':'Senior','lang':'Java','tweets':'no','phd':'no'},False),\n",
    "    ({'level':'Senior','lang':'Java','tweets':'no','phd':'yes'},False),\n",
    "    ({'level':'Mid','lang':'Python','tweets':'no','phd':'no'},True),\n",
    "    ({'level':'Junior','lang':'Python','tweets':'no','phd':'no'},True),\n",
    "    ({'level':'Junior','lang':'R','tweets':'yes','phd':'no'},True),\n",
    "    ({'level':'Junior','lang':'R','tweets':'yes','phd':'yes'},False),\n",
    "    ({'level':'Mid','lang':'R','tweets':'yes','phd':'yes'},True),\n",
    "    ({'level':'Senior','lang':'Python','tweets':'no','phd':'no'},False),\n",
    "    ({'level':'Senior','lang':'R','tweets':'yes','phd':'no'},True),\n",
    "    ({'level':'Junior','lang':'Python','tweets':'yes','phd':'no'},True),\n",
    "    ({'level':'Senior','lang':'Python','tweets':'yes','phd':'yes'},True),\n",
    "    ({'level':'Mid','lang':'Python','tweets':'yes','phd':'no'},True),\n",
    "    ({'level':'Mid','lang':'Java','tweets':'yes','phd':'no'},True),\n",
    "    ({'level':'Junior','lang':'Python','tweets':'no','phd':'yes'},False)\n",
    "]\n",
    "\n",
    "for key in ['level','lang','tweets','phd']:\n",
    "    print key,partition_entropy_by(inputs,key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang 0.4\n",
      "tweets 0.0\n",
      "phd 0.950977500433\n"
     ]
    }
   ],
   "source": [
    "senior_inputs=[(input,label) for input, label in inputs if input['level']=='Senior']\n",
    "\n",
    "for key in ['lang','tweets','phd']:\n",
    "    print key,partition_entropy_by(senior_inputs,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "def classify(tree,input):\n",
    "    if tree in [True,False]:\n",
    "        return tree\n",
    "    \n",
    "    attribute,subtree_dict=tree\n",
    "    subtree_key=input.get(attribute)\n",
    "    \n",
    "    if subtree_key not in subtree_dict:\n",
    "        subtree_key=None\n",
    "    \n",
    "    subtree=subtree_dict[subtree_key]\n",
    "    return classify(subtree,input)\n",
    "\n",
    "def build_tree_id3(inputs,split_candidates=None):\n",
    "    if split_candidates is None:\n",
    "        split_candidates=inputs[0][0].keys()\n",
    "    \n",
    "    num_inputs=len(inputs)\n",
    "    num_trues=len([label for item,label in inputs if label])\n",
    "    num_falses=num_inputs-num_trues\n",
    "    \n",
    "    if num_trues==0:return False\n",
    "    if num_falses==0:return True\n",
    "    \n",
    "    #沒有屬性可以切割的話就多數決\n",
    "    if not split_candidates:\n",
    "        return num_trues>=num_false\n",
    "    \n",
    "    best_attribute=min(split_candidates,\n",
    "                      key=partial(partition_entropy_by,inputs))\n",
    "    \n",
    "    partitions=partition_by(inputs,best_attribute)\n",
    "    new_candidates=[a for a in split_candidates if a !=best_attribute]\n",
    "    \n",
    "    subtrees={attribute_value:build_tree_id3(subset,new_candidates)\n",
    "             for attribute_value,subset in partitions.iteritems()}\n",
    "    subtrees[None]=num_trues>num_falses\n",
    "    \n",
    "    return (best_attribute,subtrees)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tree=build_tree_id3(inputs)\n",
    "\n",
    "classify(tree,{'level':'Junior','lang':'Java','tweets':'yes','phd':'no'})\n",
    "classify(tree,{'level':'Intern'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forest_classify(trees,input):\n",
    "    votes=[classify(tree,input) for tree in trees]\n",
    "    vote_counts=Counter(votes)\n",
    "    return vote_counts.most_common(1)[0][0]\n",
    "\n",
    "\n",
    "    if len(split_candidates) <=self.num_split_candidates:\n",
    "        sampled_split_candidates=split_candidates\n",
    "    \n",
    "    else:\n",
    "        sampled_split_candidtes=random.sample(split_candidates,\n",
    "                                             self.num_split_candidates)\n",
    "        \n",
    "    best_attribute=min(sampled_split_candidates,\n",
    "                      key=partial(partition_entropy_by,inputs))\n",
    "    partitions=partition_by(inputs,best_attribute)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
