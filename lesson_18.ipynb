{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c8f2d7e9cc1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[1;31m#train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m__\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[1;32mfor\u001b[0m \u001b[0minput_bector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_vector\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mbackpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_vector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "import math, collections, random\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "#neural network\n",
    "\n",
    "def step_function(x):\n",
    "    return 1 if x>=0  else 0\n",
    "\n",
    "def perceptron_output(weights,bias,x):\n",
    "    calculation=dot(weights,x)+bias\n",
    "    return step_function(calculation)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sigmoid(t):\n",
    "    return 1/(1+math.sqrt(-t))\n",
    "\n",
    "def neuron_output(weights,inputs):\n",
    "    return sigmoid(dot(weights,inputs))\n",
    "\n",
    "def feed_forward(neural_network,input_vector):\n",
    "    \n",
    "    outputs=[]\n",
    "    \n",
    "    for layer in neural_network:\n",
    "        input_with_bias=input_vector+[1]\n",
    "        output=[neuron_output(neuron,input_with_bias)\n",
    "               for neuron in layer]\n",
    "        outputs.append(output)\n",
    "        \n",
    "        input_vector=output\n",
    "    return outputs\n",
    "\n",
    "def backpropagate(network,input_vector,targets):\n",
    "    hidden_outputs,outputs=feed_forward(network,input_vector)\n",
    "    \n",
    "    output_deltas=[output*(1-output)*(output-target)\n",
    "                  for output, target in zip(outputs,targets)]\n",
    "    \n",
    "    for i, output_neuron in enumerate(network[-1]):\n",
    "        for j,hidden_output in enumerate(hidden_outputs+[1]):\n",
    "            output_neuron[j] -=output_deltas[i]*hidden_output\n",
    "    \n",
    "    hidden_deltas=[hidden_output*(1-hidden_output)*\n",
    "                  dot(output_deltas,[n[i] for n in output_layer])\n",
    "                  for i,hidden_output in enumerate(hidden_outputs)]\n",
    "    \n",
    "    for i,hidden_neuron in enumerate(network[0]):\n",
    "        for j,input in enumerate(input_vector+[1]):\n",
    "            hidden_neuron[j] -=hidden_deltas[i]*input\n",
    "\n",
    "\n",
    "zero_digit=[1,1,1,1,1,\n",
    "           1,0,0,0,1,\n",
    "           1,0,0,0,1,\n",
    "           1,0,0,0,1,\n",
    "           1,1,1,1,1]\n",
    "\n",
    "targets=[[1 if i==j else 0 for i in range(10)]\n",
    "        for j in range(10)]\n",
    "\n",
    "random.seed(0)\n",
    "input_size=25\n",
    "num_hidden=5\n",
    "output_size=10\n",
    "\n",
    "hidden_layer=[[random.random() for _ in range(input_size+1)]\n",
    "             for _ in range(num_hidden)]\n",
    "\n",
    "output_layer=[[random.random() for _ in range(num_hidden+1)]\n",
    "             for _ in range(output_size)]\n",
    "\n",
    "network=[hidden_layer,output_layer]\n",
    "\n",
    "#train model\n",
    "for __ in range(10000):\n",
    "    for input_bector,target_vector in zip(inputs,targets):\n",
    "        backpropagate(network,input_vector,target_vector)\n",
    "\n",
    "def predict(input):\n",
    "    return feed_forward(network,input)[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ploting\n",
    "\n",
    "weights=network[0][0]\n",
    "abs_weights=map(abs,weights)\n",
    "grid=[abs_weights[row:(row+5)]\n",
    "     for row in range(0,25,5)]\n",
    "\n",
    "ax=plt.gca()\n",
    "\n",
    "ax.imshow(grid,cmap=matplotlib.cm.binary,\n",
    "         interpolation='none')\n",
    "\n",
    "def patch(x,y,hatch,color):\n",
    "    return matplotlib.patches.Rectangle((x-0.5,y-0.5),1,1,\n",
    "                                       hatch=hatch,fill=False,color=color)\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if weights[5*i+j]<0:\n",
    "            ax.add_patch(patch(j,i,'/',\"white\"))\n",
    "            ax.add_patch(patch(j,i,'\\\\',\"black\"))\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
